## üè¶ Scoring de Riesgos ‚Äî Machine Learning Project

Este proyecto desarrolla un modelo de Machine Learning para evaluaci√≥n de riesgo crediticio, con el objetivo de estimar la probabilidad de impago de clientes y clasificar su nivel de riesgo para decisiones financieras.

El trabajo abarca desde el an√°lisis exploratorio hasta la creaci√≥n del pipeline de producci√≥n, empleando m√∫ltiples modelos para estimar componentes clave del riesgo financiero: PD (Probability of Default), EAD (Exposure at Default) y LGD (Loss Given Default).

---

## üéØObjetivo del Proyecto

Responder a la pregunta principal:

¬øC√≥mo identificar clientes con alto riesgo crediticio y asignarles un scoring confiable para mejorar decisiones de aprobaci√≥n?

El modelo permite priorizar pr√©stamos, minimizar p√©rdidas y apoyar estrategias de mitigaci√≥n de riesgo.

---

## üìë Datos Utilizados

- |---------- Dataset / Archivo ----------| ---------- Tipo de Informaci√≥n ----------    | ---------- Descripci√≥n ----------|

- prestamos.csv ------>   Informaci√≥n hist√≥rica de pr√©stamos y clientes ------> Base principal para modelado


--- 

## üß© Metodolog√≠a

Pipeline aplicado de forma end-to-end:
	
**1. Data Understanding**

Se realiz√≥ un an√°lisis del dataset prestamos.csv, identificando la naturaleza de las variables (num√©ricas, categ√≥ricas, comportamiento hist√≥rico), su relaci√≥n con la variable objetivo y las necesidades espec√≠ficas del negocio crediticio.
Se definieron hip√≥tesis sobre qu√© factores podr√≠an influir en el riesgo, por ejemplo: monto solicitado, historial previo, atrasos, tasa otorgada, empleo, entre otros.
     
**2. Calidad de Datos**

Se evalu√≥ la calidad de la informaci√≥n detectando valores nulos, inconsistencias, duplicados y datos at√≠picos.
Se aplicaron estrategias de imputaci√≥n, eliminaci√≥n o correcci√≥n seg√∫n su impacto en el modelo.
Tambi√©n se realizaron normalizaciones b√°sicas sobre campos temporales y monetarios.
     
**3. An√°lisis Exploratorio(EDA)**

En esta fase se exploraron correlaciones, distribuciones, y segmentaci√≥n de clientes seg√∫n riesgo.
Se detectaron patrones como caracter√≠sticas comunes en clientes que incumplieron pagos, variaci√≥n del riesgo seg√∫n ingreso, edad, o capacidad de cr√©dito.
Se generaron visualizaciones para interpretar comportamiento y validar hip√≥tesis.

**4. Feature Engineering(Transformaci√≥n de Datos)**

Se construyeron nuevas variables con potencial predictivo y se transformaron aquellas que requer√≠an preparaci√≥n antes del modelado.
Acciones aplicadas:
- Encoding de variables categ√≥ricas (One-Hot, Label Encoding)
- Escalado de variables num√©ricas (StandardScaler / MinMaxScaler seg√∫n el modelo)
- Creaci√≥n de m√©tricas derivadas (ratio deuda/ingreso, antig√ºedad crediticia, historial de pagos)
- Normalizaci√≥n de montos y scores

      
**5. Modelizaci√≥n PD - Probabilidad de Default (Clasificaci√≥n)**

Se entrenaron modelos de clasificaci√≥n para estimar la Probabilidad de Incumplimiento (PD).
Se compararon distintos algoritmos para evaluar su desempe√±o:

- Logistic Regression
- Random Forest
- XGBoost / Gradient Boosting

Se evaluaron mediante m√©tricas clave: ROC-AUC, Recall, Precision, F1-Score, priorizando detecci√≥n de casos de alto riesgo.
  
**6. Modelizaci√≥n EAD & LGD - Severidad del riesgo**

Adem√°s del riesgo de ocurrencia, se estimaron componentes financieros del riesgo crediticio:

  1. EAD (Exposure at Default) ------> Regresi√≥n ------> Cu√°nto dinero estar√≠a expuesto ante impago
  2. LGD (Loss Given Default) ------> Regresi√≥n ------> Qu√© porcentaje del cr√©dito se perder√≠a realmente

Se entrenaron modelos de regresi√≥n para predecir valores continuos usando enfoques como:
  - Random Forest Regressor
  - XGBoost Regressor
  - Linear Models / Regularizaci√≥n L1-L2

**7. Integraci√≥n de riesgo - Expected Loss**

Con PD, EAD y LGD estimados, se construy√≥ la m√©trica final:

Expected Loss = PD √ó LGD √ó EAD

Esta m√©trica permite priorizar otorgamiento de cr√©dito bas√°ndose en riesgo-coste esperado y retorno potencial.

**8.Pipeline de producci√≥n y reentramiento**

Los pasos anteriores se integraron en un pipeline reproducible usando notebooks y scripts-

Se prepar√≥ c√≥digo para:

- Cargar nuevo dataset y transformar datos autom√°ticamente
- Generar scoring y p√©rdida esperada por cliente
- Ejecutar reentrenamiento programado (batch o incremental)

--- 

## üõ†Ô∏è Herramientas usadas

- Python
- Pandas
- NumPy
- Scikit-Learn
- Matplotlib
- Seaborn
- Jupyter Notebook
